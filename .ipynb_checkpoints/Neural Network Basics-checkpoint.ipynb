{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d3cb3a-0a97-4d06-8f32-b8299d3fe84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: tensorflow in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: pillow in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (11.1.0)\n",
      "Requirement already satisfied: numpy in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: werkzeug in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from flask) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from flask) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (2.2.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (4.13.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (3.9.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from werkzeug) (3.0.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: colorama in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: rich in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\anaconda3\\envs\\tf_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask tensorflow pillow numpy werkzeug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1be7657-aa95-4657-b6f5-a1e36fa6d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"templates\", exist_ok=True)\n",
    "os.makedirs(\"static/uploads\", exist_ok=True)  # Also create the uploads folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7c6f6f9-7afa-4830-b57c-562c92ce5e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 42ms/step - accuracy: 0.7127 - loss: 0.8607 - val_accuracy: 0.9692 - val_loss: 0.0975\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 31ms/step - accuracy: 0.9365 - loss: 0.2051 - val_accuracy: 0.9586 - val_loss: 0.1272\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 31ms/step - accuracy: 0.9513 - loss: 0.1518 - val_accuracy: 0.9826 - val_loss: 0.0532\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 31ms/step - accuracy: 0.9613 - loss: 0.1227 - val_accuracy: 0.9866 - val_loss: 0.0432\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 32ms/step - accuracy: 0.9662 - loss: 0.1106 - val_accuracy: 0.9849 - val_loss: 0.0468\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 32ms/step - accuracy: 0.9704 - loss: 0.0951 - val_accuracy: 0.9882 - val_loss: 0.0353\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 33ms/step - accuracy: 0.9717 - loss: 0.0923 - val_accuracy: 0.9895 - val_loss: 0.0321\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 31ms/step - accuracy: 0.9751 - loss: 0.0855 - val_accuracy: 0.9898 - val_loss: 0.0312\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 31ms/step - accuracy: 0.9752 - loss: 0.0788 - val_accuracy: 0.9885 - val_loss: 0.0305\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 32ms/step - accuracy: 0.9775 - loss: 0.0754 - val_accuracy: 0.9903 - val_loss: 0.0284\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.9903 - loss: 0.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9903\n",
      "Model saved as digit_model.h5\n"
     ]
    }
   ],
   "source": [
    "# %%writefile train_model.py\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values (0 to 1)\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Expand dimensions for CNN (Batch, Height, Width, Channels)\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Apply data augmentation (only on training data)\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Define the CNN model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using augmented data\n",
    "model.fit(datagen.flow(x_train, y_train, batch_size=32), validation_data=(x_test, y_test), epochs=10)\n",
    "\n",
    "# Evaluate accuracy\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"digit_model.h5\")\n",
    "print(\"Model saved as digit_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6496875a-0080-4384-957f-8bbabc509f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(\"digit_model.h5\"))  # Should print True if the model is saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6487b732-d8cd-41a8-b9f8-2ada3eab8df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug: * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# %%writefile app.py\n",
    "from flask import Flask, render_template, request\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"digit_model.h5\")\n",
    "\n",
    "# Ensure upload folder exists\n",
    "UPLOAD_FOLDER = \"static/uploads\"\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "app.config[\"UPLOAD_FOLDER\"] = UPLOAD_FOLDER\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocess the image for model prediction.\"\"\"\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
    "    \n",
    "    # Ensure image is correctly oriented\n",
    "    if np.mean(img) > 127:\n",
    "        img = cv2.bitwise_not(img)  # Invert colors if needed\n",
    "\n",
    "    # Resize to 28x28 and normalize\n",
    "    img = cv2.resize(img, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    img = img / 255.0  # Normalize to [0,1]\n",
    "    \n",
    "    # Expand dimensions for CNN (Batch, Height, Width, Channels)\n",
    "    img = np.expand_dims(img, axis=(0, -1))\n",
    "\n",
    "    return img\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "def index():\n",
    "    digit = None\n",
    "    filename = None\n",
    "\n",
    "    if request.method == \"POST\":\n",
    "        file = request.files[\"file\"]\n",
    "        if file:\n",
    "            filename = file.filename\n",
    "            filepath = os.path.join(app.config[\"UPLOAD_FOLDER\"], filename)\n",
    "            file.save(filepath)\n",
    "\n",
    "            # Preprocess the image\n",
    "            processed_img = preprocess_image(filepath)\n",
    "            \n",
    "            # Predict using the model\n",
    "            prediction = model.predict(processed_img)\n",
    "            digit = np.argmax(prediction)\n",
    "\n",
    "    return render_template(\"index.html\", filename=filename, digit=digit)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c15c509-34ac-4f95-94bb-3aea753467e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting templates/index.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile templates/index.html\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Handwritten Digit Recognition</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h2>Upload an Image of a Digit (PNG with Black Background)</h2>\n",
    "    <form action=\"/\" method=\"post\" enctype=\"multipart/form-data\" onsubmit=\"return validateFile()\">\n",
    "        <input type=\"file\" id=\"fileInput\" name=\"file\" accept=\"image/png\" required>\n",
    "        <input type=\"submit\" value=\"Predict\">\n",
    "    </form>\n",
    "    \n",
    "    <script>\n",
    "        function validateFile() {\n",
    "            const fileInput = document.getElementById('fileInput');\n",
    "            const file = fileInput.files[0];\n",
    "            \n",
    "            if (!file) {\n",
    "                alert(\"Please upload a PNG image with a black background.\");\n",
    "                return false;\n",
    "            }\n",
    "            \n",
    "            // Validate file type (ensure it's PNG)\n",
    "            if (file.type !== 'image/png') {\n",
    "                alert(\"Only PNG images are allowed!\");\n",
    "                return false;\n",
    "            }\n",
    "            \n",
    "            return true;\n",
    "        }\n",
    "    </script>\n",
    "    \n",
    "    {% if filename %}\n",
    "    <h3>Uploaded Image:</h3>\n",
    "    <img src=\"{{ url_for('static', filename='uploads/' + filename) }}\" alt=\"Uploaded Image\" width=\"150\">\n",
    "    <h3>Predicted Digit: {{ digit }}</h3>\n",
    "    {% endif %}\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbb17286-cb4f-41a1-9acc-73d44ca81849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf_env\\python.exe\n",
      "3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1281bfa-45bb-4bec-aeb3-281486ed2f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f8efdc9-6451-417f-a782-0b165073d5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Save and display a few sample images\n",
    "for i in range(5):  # Save 5 sample images\n",
    "    plt.imshow(x_test[i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"digit_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.show(block=True)  # Force display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8c4cb8-aaee-48a1-bf93-7094f07b8a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a67b2-8a24-4a0b-ae6c-13957244a5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
